[{"authors":["GuangkeChen"],"categories":null,"content":"I am currently a postgraduate in ShanghaiTech University (2019.09-today), majoring in Computer Science. I am a member of System and Software Security Lab (S3L) and advised by Prof. Fu Song, the leader of S3L. I mainly focus on computer security. At present, I work on projects related with adversarial machine learing.\nI received my Bachelor\u0026rsquo;s degree (2015.09-2019.06, major: Information Engineering) in South China University of Technology, Guangzhou.\n","date":1572566400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1572566400,"objectID":"268a314c7bf590eea41ea1a69ea2512c","permalink":"/author/guangke-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/guangke-chen/","section":"authors","summary":"I am currently a postgraduate in ShanghaiTech University (2019.09-today), majoring in Computer Science. I am a member of System and Software Security Lab (S3L) and advised by Prof. Fu Song, the leader of S3L.","tags":null,"title":"Guangke Chen","type":"authors"},{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1461110400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1555459200,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]]\rname = \u0026quot;Courses\u0026quot;\rurl = \u0026quot;courses/\u0026quot;\rweight = 50\r Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]]\rname = \u0026quot;Docs\u0026quot;\rurl = \u0026quot;docs/\u0026quot;\rweight = 50\r Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":"\rClick on the Slides button above to view the built-in slides feature.\r\r\rSlides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"今天给大家推荐一篇前不久被第42届 IEEE Symposium on Security and Privacy (IEEE S\u0026amp;P, Oakland) 2021会议接收的学术论文，关于说话人识别系统的黑盒对抗攻击。\n前言 IEEE Oakland会议是信息安全四大顶级会议之一（其他三个是ACM CCS, Usenix Security, NDSS），自1980年以来，一直是介绍计算机安全和隐私发展动态的旗舰会议。该会议2010-2019年论文平均接收率为12.6%, 每年大陆学者在Oakland会议上发表论文数量不多。第42届Oakland会议将于2021年5月23日至27日在美国旧金山举办。\n论文题目为 Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems，来自\r上海科技大学 宋富教授的\rS3L (System and Software Security Lab) 课题组\n研究背景 自2013年以来，针对机器学习模型特别是深度神经网络的对抗攻击研究受到了学术界和工业界的广泛关注，相关研究工作数量也井喷式增长。然而，相关工作大多集中在图像以及语音识别领域。说话人识别，即声纹识别，作为一种生物识别技术，应用日益广泛，与此同时其安全性不容忽视。\n该论文的主要贡献是首次提出了对说话人识别系统的黑盒对抗攻击，称为FAKEBOB。FAKEBOB在开源和商用声纹识别系统（天聪智能）上均取得接近100%攻击成功率，并且能有效迁移到微软Azure声纹识别系统，包括API攻击以及实际场景下的over-the-air物理攻击。\n攻击方法 以开集说话人辨认系统 (Open-set Identification, OSI) 为例，FAKEBOB的攻击示意如图2所示，其主要思想是迭代地在一段冒名顶替者的语音上加入人耳无法感知的扰动，生成对抗语音，从而使得系统将对抗语音识别为来自说话人组中的某个（指定的）说话人。基于声纹识别技术的应用场景，攻击者可以利用FAKEBOB进行手机声纹解锁，移动应用声纹登录甚至银行交易声纹验证等，从而对受害者的财产安全，声誉等造成危害。 FAKEBOB的框架如图3所示，对抗语音生成被建模为一个带约束 (Maximal distortion) 的优化问题，约束的存在保证添加的扰动不能被人耳感知。FAKEBOB的主要特点包括：\n1）对三大不同的说话人识别任务，即开集说话人辨认，闭集说话人辨认 (Close-set Identification, CSI)，说话人确认 (Speaker Verification, SV) 均有效。FAKEBOB对不同任务采用了不同的损失函数，以适应不同说话人识别任务打分和决策的差异。\n2）和图像识别不同，开集说话人辨认以及说话人确认的决策机制基于一个预设的阈值，只有对抗语音的得分超过阈值，攻击才能成功。但在黑盒攻击模型下，攻击者无法提前获得阈值。为了解决这个问题，该论文提出了阈值估计算法，实验结果显示，该算法能很好地估计实际阈值，即保证估计阈值大于实际阈值但两者差距很小。\n3）与白盒攻击不同，FAKEBOB不要求攻击者知道系统的内部结构及参数，数据集等，只需要能够访问受害者的说话人模型（即提供输入语音，获取得分及决策结果）。这一黑盒攻击模型比白盒攻击模型更具现实性。根据调研，多数商用声纹识别系统满足黑盒模型。在黑盒攻击模型下，为了能够利用有效的梯度信息进行梯度下降解决上述优化问题，FAKEBOB使用了基于自然进化策略 (Natural Evolution Strategy, NES) 的梯度估计算法，已有文献显示基于自然进化策略的梯度估计算法比有限差分梯度估计算法更高效。\n如图4所示，FAKEBOB适用于多种不同的攻击场景\n实验结果 1）在Kaldi开源说话人识别系统上，FAKEBOB取得接近100%的攻击成功率。此外FAKEBOB对商用的天聪智能声纹识别系统也取得了100%的攻击成功率，平均API调用次数为2500次。\n2）对Decisions-only场景，FAKEBOB采用迁移攻击。实验显示，提高对抗语音的对抗强度 (Strength) 后，在开源系统之间，FAKEBOB最高能取得100%的攻击迁移成功率。此外，FAKEBOB产生的对抗语音能成功迁移到微软商用的Azure开集说话人辨认系统，针对性 (Targeted) 和非针对性 (Untargeted) 攻击迁移率分别达到26%和41%。\n3）除了API攻击，FAKEBOB对over-the-air物理攻击同样有效。Over-the-air攻击相比API攻击的难点在于，对抗语音经过扬声器播放，空气信道传播，麦克风接收后，其中的扰动会丢失从而失去对抗性。该论文通过提高对抗语音的对抗强度解决这一问题。实验结果显示这一方案是有效的，对不同的硬件设备（扬声器和麦克风），不同距离（扬声器和麦克风的距离）以及不同声学环境（相对安静，存在高斯白噪声及其他典型生活场景噪声），FAKEBOB都能取得较好的攻击成功率。\n4）为了衡量人耳对加入的扰动的感知度，该论文研究者在亚马逊MTurk平台上进行了两项问卷调查。第一项调查询问参与者是否听到语音中存在噪声，第二项调查询问参与者认为原始语音和对抗语音是否来自同一个说话人。如图5所示，尽管参与者对Over-the-air攻击语音的感知要比API攻击明显，但该结果和已有相似调查具有可比性。第二个调查结果显示，在人耳听起来是来自冒名顶替者的语音却能使得系统错误决策。\n5）最后，该论文还验证了FAKEBOB在若干个对抗语音防御或检测方法下的攻击效果。结果显示，对于下采样、中值滤波和比特量化这三种输入变换类的防御方法，通过产生强对抗性语音，FAKEBOB能够逃避这些防御方法，并且这三种方法在增加攻击开销或降低攻击成功率方面效果有限或无效；对于基于时序依赖性的对抗语音检测方法 (Temporal Dependency Detection)，由于FAKEBOB并没有改变语音的文本内容，保留了时序依赖性，因此该检测方法接近于随机猜测。\n后记 需要注意的是，针对说话人识别的安全威胁还有一类，称为欺骗攻击（Spoofing Attack）。欺骗攻击通过录制或语音合成等方法获取某段语音，该语音人耳听起来像受害者发出，自然地就能被系统识别为来自受害者；而对抗攻击利用的是系统的漏洞，尽管生成的语音人耳听起来根本不像受害者发出，但系统仍然做出错误决策。对抗攻击相比欺骗攻击的优势在于，当有熟悉受害者声音的人（包括受害者自身）在场时，对抗攻击相比欺骗攻击更加隐蔽。\n如果你想深入了解这项工作，可以参考以下资料：\n\r论文PDF\n\rFAKEBOB项目主页，需科学上网\n\rFAKEBOB Github开源代码\n\rFAKEBOB Gitee开源代码\n最后，欢迎关注 上科大系统与软件安全实验室S3L 微信公众号，更多信息安全方面的前沿动态，等你一起发掘！课题组也持续招收研究生、博后、研究员、实习及访问学生。 ","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590624000,"objectID":"494d0af030bd1e75482f94fbce87fea8","permalink":"/post-research/fakebob/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/post-research/fakebob/","section":"post-research","summary":"今天给大家推荐一篇前不久被第42届 IEEE Symposium on Security and Privacy (IEEE S\u0026amp;P, Oakland) 2021会议接收的学术论文，关于说话人识别系统的黑盒对抗攻击。\n","tags":null,"title":"Computer Security Paper Sharing 01 - S\u0026P 2021 FAKEBOB","type":"post-research"},{"authors":["Guangke Chen"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --\r","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"7fd8af56d00258184dcb18e73a8e633a","permalink":"/publication/sp2021-fakebob/","publishdate":"2020-04-15T00:00:00Z","relpermalink":"/publication/sp2021-fakebob/","section":"publication","summary":"Guangke Chen; Sen Chen; Lingling Fan; Xiaoning Du; Zhe Zhao; Fu Song; Yang Liu. Accepted by the 42nd IEEE Symposium on Security and Privacy (IEEE S\u0026P, Oakland), 2021. The first pratical black-box adversarial attack against speaker recognition systems.","tags":["Computer Security"],"title":"Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r```\r renders as\nimport pandas as pd\rdata = pd.read_csv(\u0026quot;data.csv\u0026quot;)\rdata.head()\r Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}\r{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\r renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\\r1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\r renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\r renders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\r renders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\r renders as\ngantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r An example class diagram:\n```mermaid\rclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r```\r renders as\nclassDiagram\rClass01 \u0026lt;|-- AveryLongClass : Cool\r\u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01\rClass09 --\u0026gt; C2 : Where am i?\rClass09 --* C3\rClass09 --|\u0026gt; Class07\rClass07 : equals()\rClass07 : Object[] elementData\rClass01 : size()\rClass01 : int chimp\rClass01 : int gorilla\rclass Class10 {\r\u0026lt;\u0026lt;service\u0026gt;\u0026gt;\rint id\rsize()\r}\r An example state diagram:\n```mermaid\rstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r```\r renders as\nstateDiagram\r[*] --\u0026gt; Still\rStill --\u0026gt; [*]\rStill --\u0026gt; Moving\rMoving --\u0026gt; Still\rMoving --\u0026gt; Crash\rCrash --\u0026gt; [*]\r Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example\r- [x] Write diagram example\r- [ ] Do something else\r renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header |\r| ------------- | ------------- |\r| Content Cell | Content Cell |\r| Content Cell | Content Cell |\r renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}}\rA Markdown aside is useful for displaying notices, hints, or definitions to your readers.\r{{% /alert %}}\r renders as\n\rA Markdown aside is useful for displaying notices, hints, or definitions to your readers.\r\r\rSpoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}}\rYou found me!\r{{\u0026lt; /spoiler \u0026gt;}}\r renders as\n\rClick to view the spoiler\r\rYou found me!\r\r\r Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R\r renders as\n\r Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"d9e024d4c41c739d3e89c589d8e207fa","permalink":"/post-backup/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post-backup/writing-technical-content/","section":"post-backup","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post-backup"},{"authors":["Nelson Bighetti"],"categories":null,"content":"\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"584b6d508de28ddeeb33dda4f5ce0e96","permalink":"/publication-backup/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication-backup/preprint/","section":"publication-backup","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication-backup"},{"authors":["Nelson Bighetti"],"categories":[],"content":"from IPython.core.display import Image\rImage('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')\r print(\u0026quot;Welcome to Academic!\u0026quot;)\r Welcome to Academic!\r Install Python and JupyterLab \rInstall Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rcd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/\rjupyter lab index.ipynb\r The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (\rfront matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n---\rtitle: My post's title\rdate: 2019-09-01\r# Put any other Academic metadata here...\r---\r Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.\r Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"45222a08367701156c40be7279228e05","permalink":"/post-backup/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post-backup/jupyter/","section":"post-backup","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post-backup"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic \rAcademic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click \rPDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? \rAsk\n\rDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"本文主要以ORL_64x64人脸数据库识别为例，介绍如何使用基于matlab的CDBN工具箱。至于卷积深度置信网络（CDBN，Convolutional Deep Belief Network）的理论知识，只给出笔者整理的一些学习资源。\n卷积深度置信网络理论知识 参考以下学习资料\n \rCSDN博客\u0026mdash;受限玻尔兹曼机（RBM）学习笔记 \rCSDN博客\u0026mdash;深度信念网络(Deep Belief Network) \r知乎\u0026mdash;卷积神经网络工作原理直观的解释 \r量子位公众号\u0026mdash;一文了解各种卷积结构原理及优劣 \r中国知网博硕论文\u0026mdash;基于卷积深度置信网络的歌手识别 \rCDBN paper（全英）  CDBN工具箱简介 据笔者了解，目前，比较流行的深度学习框架，如TensorFlow、DeepLearning4j等不支持CDBN。GitHub上有基于Matlab的CDBN工具箱：\rCDBN工具箱下载链接 下面简要介绍该工具箱。 从GitHub上下载的压缩包解压后再打开，文件目录如下：\n其中，最为重要的肯定是toolbox。toolbox里面有三个lib,分别是CDBN，DBN，Softmax库。本文将用到CDBN和Softmax两个库。\n需要注意的是，由于这个工具箱不是官方版的，因此可能存在某些bug，后面会涉及到笔者使用工具箱过程中的一些经验。\n神经网络结构 介绍一下本文搭建的进行人脸识别的卷积深度置信网络的结构。\n  主体结构：两个卷积受限玻尔兹曼机（CRBM，Convolutional Restricted Boltzmann Machine）堆叠（每个CRBM后都接有池化层），顶层采用Softmax，实现分类。\n  第一个CRBM：\n   第二个CRBM：    Softmax层 神经元个数40个，最大迭代次数maxIter=1000，代价函数为交叉熵代价函数（Cross-Entropy Error）\n  其他参数 其他诸如学习速率等的参数使用CDBN-master\\toolbox\\CDBNLIB\\default_layer2D.m中的默认值。\n  编程 以下讲解编程步骤。\n  步骤一：安装工具箱 只需运行setup_toolbox.m即可。 安装工具箱其实只是把用到的一些函数添加到matlab的搜索路径，因此你完全可以把工具箱内所有的文件都复制到你当前的路径下，不过肯定麻烦啦！\n  步骤二：加载和矩阵化数据\n   %load data\rdataFortrain=load('ORL_64x64\\StTrainFile1.txt');%注意修改路径\rtrain_data=dataFortrain(:,1:end-1)';%训练样本\rtrain_data=reshape(train_data,[64,64,1,360]);%矩阵化训练样本\rtrainL=dataFortrain(:,end);%训练样本标签\rdataFortest=load('ORL_64x64\\StTestFile1.txt');%注意修改路径\rtest_data=dataFortest(:,1:end-1)';%测试样本\rtest_data=reshape(test_data,[64,64,1,40]);%注意修改路径\rtestL=dataFortest(:,end);%测试样本标签\r 重点讲一下第四行。 StTrainFile1.txt中有360行，4097列。每一行是一幅人脸图像（像素为64X64=4096）的4096个灰度值，最后一列是该幅人脸图像的标签（1-40），表明其属于哪个人的（共40人，即分类数目为40）。由此可见，一幅二维图像（矩阵）被拉成了向量进行存储，因此在数据输入CDBN前，我们要对向量进行矩阵化，调用matlab的reshape方法，最终生成一个4维的矩阵，四个维度分别是64,64,1,360（样本数）。倒数第二行同理。\n 步骤三：定义层参数 工具箱把一层layer定义为一个struct对象。   %INITIALIZE THE PARAMETERS OF THE NETWORK %first layer setting\rlayer{1} = default_layer2D();\rlayer{1}.inputdata=train_data;%输入训练样本\rlayer{1}.n_map_v=1;\rlayer{1}.n_map_h=9;\rlayer{1}.s_filter=[7 7];\rlayer{1}.stride=[1 1];\rlayer{1}.s_pool=[2 2];\rlayer{1}.batchsize=90;\rlayer{1}.n_epoch=1;\r------------------------------------------------------------------------------------------------------------------------\r%second layer setting\rlayer{2} = default_layer2D();\rlayer{2}.n_map_v=9;\rlayer{2}.n_map_h=16;\rlayer{2}.s_filter=[5 5];\rlayer{2}.stride=[1 1];\rlayer{2}.s_pool=[2 2];\rlayer{2}.batchsize=10;\rlayer{2}.n_epoch=1;\r 需要注意的是，**layer{i}=default_layer2D()这条语句是必须的，且必须位于所有层参数定义语句的最前面。**原因：如果layer{i}=default_layer2D()这条语句不位于最前面的话，在这条语句前面的参数赋值语句实质不起作用，这些参数还是取默认值。特别是对于第一层，因为default_layer2D()方法中是没有定义inputdata字段的，如果layer{1}.inputdata=train_data这条语句位于layer{1}=default_layer2D()前面，则会出现“使用未定义字段”的错误。 补充：要注意根据自己使用的数据集的情况设定层的输入类型，对[0,1]之间的数据集，应该使用二值神经网络，设定 layer{i}.type_input = \u0026lsquo;Binary\u0026rsquo;(程序默认);其他数据集，应该设为layer{i}.type_input = \u0026lsquo;Gaussian\u0026rsquo;;至于二者的区别，自行百度，这里不展开了。\n 步骤四：训练CDBN网络 这个过程是无监督学习，只需调用cdbn2D方法即可。  在调用cdbn2D方法之前，CDBN-master\\toolbox\\CDBNLIB\\mex中的crbm_forward2D_batch_mex.c要先用mex命令编译生成crbm_forward2D_batch_mex.mexw64文件才能供matlab调用\nmex crbm_forward2D_batch_mex.c\r 在编译前，crbm_forward2D_batch_mex.c要先修改：128行的out_id要改成在最开始的位置定义，否则编译时会出现“缺少：在类型前面’”的报错信息（PS:第一次遇到这么奇葩的报错，当时怀疑C语言是不是白学了），原因：VS2010的C编译器只支持C89标准，对C99标准支持不完全，而在C89标准中，变量需要放到函数体的前面声明，先声明再使用。\n%% ----------- GO TO 2D CONVOLUTIONAL DEEP BELIEF NETWORKS ------------------%% tic;\r[model,layer] = cdbn2D(layer);\rsave('model_parameter','model','layer');\rtoc;\rtrainD = model{1}.output;%训练样本的第一个CRBM的输出，是一个4维矩阵\rtrainD1 = model{2}.output;%训练样本的第二个CRBM的输出，是一个4维矩阵\r 我们来比较一下train_data、trainD、trainD1的大小\n现在再看看卷积神经网络的图示，是不是很好理解了呢？\n 步骤五：将测试样本输入训练好的CDBN网络，提取高维特征  这段代码可以直接copy，修改好变量名即可！\n%% ------------ TESTDATA FORWARD MODEL WITH THE PARAMETERS ------------------ %%\r% FORWARD MODEL OF NETWORKS\rH = length(layer);\rlayer{1}.inputdata = test_data;\rfprintf('output the testdata features:\u0026gt;\u0026gt;...\\n');\rtic;\rif H \u0026gt;= 2\r% PREPROCESSS INPUTDATA TO BE SUITABLE FOR TRAIN layer{1} = preprocess_train_data2D(layer{1});\rmodel{1}.output = crbm_forward2D_batch_mex(model{1},layer{1},layer{1}.inputdata);\rfor i = 2:H\rlayer{i}.inputdata = model{i-1}.output;\rlayer{i} = preprocess_train_data2D(layer{i});\rmodel{i}.output = crbm_forward2D_batch_mex(model{i},layer{i},layer{i}.inputdata);\rend\relse\rlayer{1} = preprocess_train_data2D(layer{1});\rmodel{1}.output = crbm_forward2D_batch_mex(model{1},layer{1},layer{1}.inputdata);\rend\rtestD = model{1}.output;%训练样本的第一个CRBM的输出，是一个4维矩阵\rtestD1 = model{2}.output;%训练样本的第二个CRBM的输出，是一个4维矩阵\rtoc;\r 同样的，我们来看一下test_data、testD、testD1的大小：\n 步骤六：训练Softmax分类器，同时进行识别 这里我们用到 softmaxExercise(inputData,labels,inputData_t,labels_t)这个函数 参数说明： **- inputdata:**训练样本的CDBN输出，要求是二维矩阵 **-labels:**训练样本的标签 **-inputData_t:**测试样本的CDBN输出，要求是二维矩阵 **-labels_t:**测试样本的标签 由于CDBN的输出是4维矩阵，因此在训练Softmax分类器前，需要把矩阵拉成向量（和之前的过程相反）。代码如下，可直接copy，修改变量名即可！   %% ------------------------------- Softmax ---------------------------------- %%\rfprintf('train the softmax:\u0026gt;\u0026gt;...\\n');\rtic;\r% TRANSLATE THE OUTPUT TO ONE VECTOR\rtrainDa = [];\rtrainLa=trainL;\rfor i= 1:size(trainD,4)\ra1 = [];\ra2 = [];\ra3 = [];\rfor j = 1:size(trainD,3)\ra1 = [a1;reshape(trainD(:,:,j,i),size(trainD,2)*size(trainD,1),1)];\rend\rfor j = 1:size(trainD1,3)\ra2 = [a2;reshape(trainD1(:,:,j,i),size(trainD1,2)*size(trainD1,1),1)];\rend\ra3 = [a3;a1;a2];\rtrainDa = [trainDa,a3];\rend\rtestDa = [];\rtestLa=testL;\rfor i= 1:size(testD,4)\rb1 = [];\rb2 = [];\rb3 = [];\rfor j = 1:size(testD,3)\rb1 = [b1;reshape(testD(:,:,j,i),size(testD,2)*size(testD,1),1)];\rend\rfor j =1:size(testD1,3)\rb2 = [b2;reshape(testD1(:,:,j,i),size(testD1,2)*size(testD1,1),1)];\rend\rb3 = [b3;b1;b2];\rtestDa = [testDa,b3];\rend\r 我们来看一下拉成向量后的trainDa以及testDa的大小\n对比一下，train_data和test_data在矩阵化之前的大小：\n可见，CDBN作为特征提取器，将4096维特征映射到了9873维特征，提高了Softmax的分类能力！\nsoftmaxExercise.m中有这样一段注释：\n因此在调用softmaxExercise方法前，要做以下4个工作：\n 修改softmaxExercise.m第22行的numClasses，如本文改为40 修改softmaxExercise.m第96行的maxIter，本文取1000  PS:个人觉得softmaxExercise方法应该增加两个入口参数，即numClasses和maxIter，如此才能更好体现封装的思想。\n  softmaxCost.m中定义需要的损失函数，只需要改第90行\ncost = -(1. / numCases) * sum(sum(groundTruth .* log(p))) + (lambda / 2.) * sum(sum(theta.^2)); 这条语句即可，原文件使用的是交叉熵代价函数。\n  有必要的话可以修改 softmaxPredict.m中内容，个人觉得完全没必要，保留即可。\n  最后调用softmaxExercise方法\nsoftmaxExercise(trainDa,trainLa,testDa,testLa);\rtoc;\r  完整代码\n FaceRecognitionDemo.m\rclear;\r%load data\rdataFortrain=load('ORL_64x64\\StTrainFile1.txt');\rtrain_data=dataFortrain(:,1:end-1)';\rtrain_data=reshape(train_data,[64,64,1,360]);\rtrainL=dataFortrain(:,end);\rdataFortest=load('ORL_64x64\\StTestFile1.txt');\rtest_data=dataFortest(:,1:end-1)';\rtest_data=reshape(test_data,[64,64,1,40]);\rtestL=dataFortest(:,end);\r%INITIALIZE THE PARAMETERS OF THE NETWORK %first layer setting\rlayer{1} = default_layer2D();\rlayer{1}.inputdata=train_data;\rlayer{1}.n_map_v=1;\rlayer{1}.n_map_h=9;\rlayer{1}.s_filter=[7 7];\rlayer{1}.stride=[1 1];\rlayer{1}.s_pool=[2 2];\rlayer{1}.batchsize=90;\rlayer{1}.n_epoch=1;\r%second layer setting\rlayer{2} = default_layer2D();\rlayer{2}.n_map_v=9;\rlayer{2}.n_map_h=16;\rlayer{2}.s_filter=[5 5];\rlayer{2}.stride=[1 1];\rlayer{2}.s_pool=[2 2];\rlayer{2}.batchsize=10;\rlayer{2}.n_epoch=1;\r%% ----------- GO TO 2D CONVOLUTIONAL DEEP BELIEF NETWORKS ------------------ %% tic;\r[model,layer] = cdbn2D(layer);\rsave('model_parameter','model','layer');\rtoc;\rtrainD = model{1}.output;\rtrainD1 = model{2}.output;\r%% ------------ TESTDATA FORWARD MODEL WITH THE PARAMETERS ------------------ %%\r% FORWARD MODEL OF NETWORKS\rH = length(layer);\rlayer{1}.inputdata = test_data;\rfprintf('output the testdata features:\u0026gt;\u0026gt;...\\n');\rtic;\rif H \u0026gt;= 2\r% PREPROCESSS INPUTDATA TO BE SUITABLE FOR TRAIN layer{1} = preprocess_train_data2D(layer{1});\rmodel{1}.output = crbm_forward2D_batch_mex(model{1},layer{1},layer{1}.inputdata);\rfor i = 2:H\rlayer{i}.inputdata = model{i-1}.output;\rlayer{i} = preprocess_train_data2D(layer{i});\rmodel{i}.output = crbm_forward2D_batch_mex(model{i},layer{i},layer{i}.inputdata);\rend\relse\rlayer{1} = preprocess_train_data2D(layer{1});\rmodel{1}.output = crbm_forward2D_batch_mex(model{1},layer{1},layer{1}.inputdata);\rend\rtestD = model{1}.output;\rtestD1 = model{2}.output;\rtoc;\r%% ------------------------------- Softmax ---------------------------------- %%\rfprintf('train the softmax:\u0026gt;\u0026gt;...\\n');\rtic;\r% TRANSLATE THE OUTPUT TO ONE VECTOR\rtrainDa = [];\rtrainLa=trainL;\rfor i= 1:size(trainD,4)\ra1 = [];\ra2 = [];\ra3 = [];\rfor j = 1:size(trainD,3)\ra1 = [a1;reshape(trainD(:,:,j,i),size(trainD,2)*size(trainD,1),1)];\rend\rfor j = 1:size(trainD1,3)\ra2 = [a2;reshape(trainD1(:,:,j,i),size(trainD1,2)*size(trainD1,1),1)];\rend\ra3 = [a3;a1;a2];\rtrainDa = [trainDa,a3];\rend\rtestDa = [];\rtestLa=testL;\rfor i= 1:size(testD,4)\rb1 = [];\rb2 = [];\rb3 = [];\rfor j = 1:size(testD,3)\rb1 = [b1;reshape(testD(:,:,j,i),size(testD,2)*size(testD,1),1)];\rend\rfor j =1:size(testD1,3)\rb2 = [b2;reshape(testD1(:,:,j,i),size(testD1,2)*size(testD1,1),1)];\rend\rb3 = [b3;b1;b2];\rtestDa = [testDa,b3];\rend\rsoftmaxExercise(trainDa,trainLa,testDa,testLa);\rtoc;\r  运行截图及准确率\n 97.5%的识别率，还是可以接受的，一方面是数据集好，另一方面是搭建得网络好。 读者可以试一试调整CDBN网络的参数，比如增大epoch（本文取1），看能否获得更高的识别率。 为了方便读者研究，附上所有文件。\n\r本Demo文件汇总下载链接（原链接失效，此为新版连接）,提取码：7f6i\n以下是使用此工具箱的几点提示：\n 原始工具箱只在LINUX系统测试过，由于LINUX系统和WINDOWS系统的文件分隔符不同， 因此DemoCDBN_Binary_2D.m的第83行、 cdbn2D.m的第15、24行、 setup_toolbox.m的文件分隔符要修改。 源程序存在bug，即若样本个数不是batchsize的整数倍的话，会出错，因此在此bug排除前，应将batchsize设置为样本数目的因数 类别标签不要用负数或0，比如进行二分类，标签不要设为-1和1，可以设为1和2，这是因为softmaxCost.m文件中的第18行建立稀疏矩阵时会以标签作为矩阵的索引，如果设为0或负数，肯定会报错：矩阵索引必须为正数  ","date":1503187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503187200,"objectID":"ce06d3c80cbd0bf01076ee599feb7c66","permalink":"/post-tech/conv-dbn/","publishdate":"2017-08-20T00:00:00Z","relpermalink":"/post-tech/conv-dbn/","section":"post-tech","summary":"本文主要以ORL_64x64人脸数据库识别为例，介绍如何使用基于matlab的CDBN工具箱。至于卷积深度置信网络（CDBN，Convolutional Deep Belief Network）的理论知识，只给出笔者整理的一些学习资源。\n","tags":null,"title":"卷积深度置信网络工具箱的使用---人脸识别","type":"post-tech"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Nelson Bighetti","吳恩達"],"categories":["Demo","教程"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n\rCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤️ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute    \r\rAcademic is mobile first with a responsive design to ensure that your site looks stunning on every device.\r\r\rKey features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n\rChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  \rAcademic Admin: An admin tool to import publications from BibTeX or import assets for an offline site \rAcademic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n \rone-click install using your web browser (recommended) \rinstall on your computer using Git with the Command Prompt/Terminal app \rinstall on your computer by downloading the ZIP files \rinstall on your computer with RStudio  Then personalize and deploy your new site.\nUpdating \rView the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"fef2f176530932366efab1c61ff424b1","permalink":"/post-backup/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post-backup/getting-started/","section":"post-backup","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","开源"],"title":"Academic: the website builder for Hugo","type":"post-backup"},{"authors":["Nelson Bighetti","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"2582f41b952d88c2010b06abe9d3bada","permalink":"/publication-backup/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication-backup/journal-article/","section":"publication-backup","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication-backup"},{"authors":["Nelson Bighetti","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"6ca84d652d4becb491eb0f59d8e99842","permalink":"/publication-backup/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication-backup/conference-paper/","section":"publication-backup","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication-backup"}]